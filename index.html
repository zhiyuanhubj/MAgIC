<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="MAgIC: Benchmarking Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration"/>
  <meta property="og:description" content="MAgIC: A novel benchmarking framework specifically tailored to assess LLMs within multi-agent settings, providing quantitative metrics to evaluate their judgment, reasoning, deception, self-awareness, cooperation, coordination, and rationality."/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/banner.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="MAgIC: Benchmarking Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration">
  <meta name="twitter:description" content="MAgIC: A novel benchmarking framework specifically tailored to assess LLMs within multi-agent settings, providing quantitative metrics to evaluate their judgment, reasoning, deception, self-awareness, cooperation, coordination, and rationality.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/banner.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Instruction optimization">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>MAgIC</title>
  <link rel="icon" type="image/x-icon" href="static/images/nus-logo.jpeg">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title"><font color="#1155cc">MAgIC</font>: Benchmarking Large Language Model Powered <u>M</u>uulti-<u>A</u>ugent in Co<u>g</u>nition, Audaptab<u>i</u>ulity, Rat<u>i</u>uonality and <u>C</u>uollaboration </h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
                    <a href="https://scholar.google.com/citations?user=_Gu69coAAAAJ&hl=zh-CN" target="_blank">Lin Xu*</a>,
                  </span>
                  <span class="author-block">
                    <a href="https://zhiyuanhubj.github.io/" target="_blank">Zhiyuan Hu*</a>,
                  </span>
                  <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=DdCAbWwAAAAJ&hl=en" target="_blank">Daquan Zhou#</a>,
                  </span>
                  <span class="author-block">
                    <a href="https://hyren.me/" target="_blank">Hongyu Ren</a>,
                  </span>
                  <span class="author-block">
                    <a href="https://dong-zhen.com/" target="_blank">Zhen Dong#</a>,
                  </span>
                  <span class="author-block">
                    <a href="https://people.eecs.berkeley.edu/~keutzer/" target="_blank">Kurt Keutzer</a>,
                  </span>
                  <span class="author-block">
                    <a href="https://www.comp.nus.edu.sg/~ngsk/" target="_blank">See-Kiong Ng</a>,
                  </span>
                  <span class="author-block">
                    <a href="https://sites.google.com/site/jshfeng/home" target="_blank">Jiashi Feng</a>
                  </span>
                  </div>
                  <div class="is-size-5 publication-authors">
                    <span class="author-block">National University of Singapore, </span>
                    <span class="author-block">ByteDance</span><br>
                    <span class="author-block">Stanford Unversity, </span>
                    <span class="author-block">UC Berkeley</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Equal Contribution</small></span>
                    <span class="eql-cntrb"><small><sup>#</sup>Corresponding authors</small></span>
                  </div>
                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2310.02905.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>


                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/cathyxl/MAgIC" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- Evaluation Library Link -->
                <span class="link-block">
                  <a href="https://pypi.org/project/llm-agent/0.3.0/" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Library</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <iframe width="560" height="315" src="https://www.youtube.com/embed/kBGbnMl1EwI" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    </div>
  </div>
</section> -->
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3"><font color="#1155cc">Abstract</font></h2>
        <div class="content has-text-justified">
          <p>
          Large Language Models (LLMs) have marked a significant advancement in the field of natural language processing, demonstrating exceptional capabilities in reasoning, tool usage, and memory. As their applications extend into multi-agent environments, a need has arisen for a comprehensive evaluation framework that captures their abilities in reasoning, planning, collaboration, and more. This work introduces a novel benchmarking framework specifically tailored to assess LLMs within multi-agent settings, providing quantitative metrics to evaluate their judgment, reasoning, deception, self-awareness, collaboration, coordination, and rationality. We utilize games such as Chameleon and Undercover, alongside game theory scenarios like Cost Sharing, Multi-player Prisoner's Dilemma, and Public Good, to create diverse testing environments. Our framework is fortified with the Probabilistic Graphical Modeling (PGM) method, enhancing the LLMs' capabilities in navigating complex social and cognitive dimensions. The benchmark evaluates seven multi-agent systems powered by different LLMs, quantitatively highlighting a significant capability gap over threefold between the strongest, GPT-4, and the weakest, Llama-2-70B. It also confirms that our PGM enhancement boosts the inherent abilities of all selected models by 50\% on average.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="section hero">
  <div class="container is-max-desktop">
    <!-- Title Section -->
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3"><font color="#1155cc">How about current LLMs-powered Multi-agent's capabilities</font></h2>
      </div>
    </div>
  </div>

  <div class="container">
    <!-- Image Section -->
    <div class="columns is-centered">
      <div class="column is-three-fifths">
        <div class="item">
          <!-- Replace with an image in supported format (e.g., JPG, PNG) -->
          <img src="static/images/rader.jpg" alt="JPG">
        </div>
      </div>
    </div>

    <!-- Text Section -->
    <div class="columns is-centered">
      <div class="column is-three-fifths">
        <p class="smaller-text">
          <div style="padding-top: 8px;">
            The radar diagram on the left illustrates the performance of LLMs across various metrics. In the figure, "-T" denotes "-turbo", and "+P" denotes that the model has been augmented with PGM. The bar chart on the right denotes the area occupied in the radar diagram and the red line plots the average winning rates in all games. It is clearly observed that the larger the area occupied in the radar diagram, the higher the winning rates are. This justifies that the proposed evaluation metrics are good to reflect the capability of the language models. For more details please refer to Sec.<br>
          </div>
          <!-- Other Steps -->
        </p>
      </div>
    </div>
  </div>
</section>


<hr class="solid">

<section class="section">
  <!-- 标题部分 -->
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3"><font color="#1155cc">Benchmarking Environment</font></h2>
      </div>
    </div>
  </div>

  <!-- 子标题部分 -->
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h3 class="title is-4"><font color="#1155cc">We assess Multi-agent's abilities in Chameleon, Undercover, and Game Theory Scenarios (Cost Sharing, Prisoner’s Dilemma and Public Good)</font></h3>
      </div>
    </div>
  </div>

  <!-- 图像部分 -->
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <img src="static/images/env.jpg" alt="JPG">
      </div>
    </div>
  </div>
</section>


<section class="section">

  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3"><font color="#1155cc">Instruction induction</font></h2>
        <p>
          Our approach significantly outperforms APE and InstructZero in a variety of instruction induction tasks.
        </p>
      </div>
    </div>
  </div>

  <div class="container is-max-desktop">
    <div class="columns is-centered  has-text-centered">

      <div class="column is-three-fifths">
      <div class="column">
        <div class="content">
          <h2 class="subtitle has-text-centered"></h2>Figure 1: Improvement of our INSTINCT over baselines (in 30 tasks).</h2>
            <img src="static/images/ii1.png" alt="II Image">
        </div>
      </div>
      </div>

      <div class="column is-three-fifths">
      <div class="column">
        <div class="content">
          <h2 class="subtitle has-text-centered"></h2>Table 1: Average test accuracy achieved by (i) APE, (ii) InstructZero and (iii) INSTINCT.</h2>
          <img src="static/images/ii2.png" alt="II Table">
        </div>
      </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      
      <!-- <div class="container is-three-fifths"> -->
        <div class="column is-two-fifths">
          <div class="content">
            <h3 class="title is-3"><font color="#1155cc">Improving instruction for summarization tasks</font></h3>
            <p>
              We demonstrate the capability of our INSTINCT in instruction optimization for the task of text summarization.
            </p>
          </div>
        </div>
      <!-- </div> -->

      <!-- <div class="container is-three-fifths"> -->
        <div class="column has-text-centered">
        <div class="column">
          <div class="content">
            <h2 class="subtitle has-text-centered"></h2>Table 2: Instruction optimization on SAMSum dataset (summarization task).</h2>
            <img src="static/images/sum.png" alt="Sum Table">
          </div>
        </div>
        <!-- </div> -->
      </div>
    <!-- </div> -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-two-fifths">
        <div class="content">
          <h3 class="title is-3"><font color="#1155cc">Improving zero-shot chain-of-thought prompts</font></h3>
          <p>
            We improve zero-shot CoT prompts on multiple arithmetic reasoning tasks.
          </p>
        </div>
      </div>

      <div class="column has-text-centered">
        <div class="column">
          <div class="content">
            <h2 class="subtitle has-text-centered"></h2>Table 3: The best zero-shot CoT instructions found by different algorithms and their scores.</h2>
            <img src="static/images/cot.png" alt="CoT Table">
            <img src="static/images/smart.webp" alt="brain">
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-two-fifths">
        <div class="content">
          <h3 class="title is-3"><font color="#1155cc">Further improvement with one-shot in-context learning</font></h3>
          <p>
            We see wider potential applications of our INSTINCT through its combination with in-context learning.
          </p>
        </div>
      </div>

      <div class="column has-text-centered">
        <div class="column">
          <div class="content">
            <h2 class="subtitle has-text-centered"></h2>Table 4: Average test accuracy achieved by (i) INSTINCT, (ii) test-time-only one-shot INSTINCT, (iii) one-shot INSTINCT. The results including all tasks are given in the paper.</h2>
            <img src="static/images/oneshot.png" alt="One-shot Table">
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<hr class="solid">

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title has-text-centered"><font color="#1155cc">BibTeX</font></h2>
      <pre><code>@article{lin2023use,
        title={Use Your {INSTINCT}: INSTruction optimization usIng Neural bandits Coupled with Transformers},
        author={Xiaoqiang Lin and Zhaoxuan Wu and Zhongxiang Dai and Wenyang Hu and Yao Shu and See-Kiong Ng and Patrick Jaillet and Bryan Kian Hsiang Low},
        year={2023},
        eprint={2310.02905},
        archivePrefix={arXiv},
        primaryClass={cs.LG}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->

<style>
  .max-width-1 {
    max-width: 900px;
  }
  
  .max-width-2 {
    max-width: 500px;
  }
  .max-width-3 {
    max-width: 800px;
  }
  .max-width-4 {
    max-width: 800px;
  }
  .max-width-5 {
    max-width: 700px;
  }
</style>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->



    <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">
              <p>
                This website is licensed under a <a rel="license"
                                                    href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
                The website template is borrowed from <a href="https://github.com/nerfies/nerfies.github.io"> here</a>.
              </p>
              <a href="https://info.flagcounter.com/UgUq"><img src="https://s11.flagcounter.com/count2/UgUq/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_10/viewers_0/labels_0/pageviews_0/flags_0/percent_0/" alt="Flag Counter" border="0"></a>
            </div>
          </div>
        </div>
      </div>
    </footer>

</body>
</html>
